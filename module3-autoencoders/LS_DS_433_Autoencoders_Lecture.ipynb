{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-DNN (Python 3.7)",
      "language": "python",
      "name": "u4-s3-dnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_433_Autoencoders_Lecture.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekoly/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module3-autoencoders/LS_DS_433_Autoencoders_Lecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBvazgQpaAIi",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 3, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YUHs_mQbqmr",
        "colab_type": "code",
        "outputId": "b388d400-fca2-4e39-c8c6-96a0ca80bedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 64kB/s \n",
            "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.27.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 36.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (45.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm22mALXb70q",
        "colab_type": "code",
        "outputId": "b2a1b8ad-80ec-4190-a1e7-e9935ad37a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8a-ko1zaAIl",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoders\n",
        "\n",
        "> An autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner.[1][2] The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore signal “noise”. Along with the reduction side, a reconstructing side is learnt, where the autoencoder tries to generate from the reduced encoding a representation as close as possible to its original input, hence its name. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DtsycH7aAIm",
        "colab_type": "text"
      },
      "source": [
        "## Learning Objectives\n",
        "*At the end of the lecture you should be to*:\n",
        "* <a href=\"#p1\">Part 1</a>: Describe the componenets of an autoencoder\n",
        "* <a href=\"#p2\">Part 2</a>: Train an autoencoder\n",
        "* <a href=\"#p3\">Part 3</a>: Apply an autoenocder to a basic information retrieval problem\n",
        "\n",
        "__Problem:__ Is it possible to automatically represent an image as a fixed-sized vector even if it isn’t labeled?\n",
        "\n",
        "__Solution:__ Use an autoencoder\n",
        "\n",
        "Why do we need to represent an image as a fixed-sized vector do you ask? \n",
        "\n",
        "* __Information Retrieval__\n",
        "    - [Reverse Image Search](https://en.wikipedia.org/wiki/Reverse_image_search)\n",
        "    - [Recommendation Systems - Content Based Filtering](https://en.wikipedia.org/wiki/Recommender_system#Content-based_filtering)\n",
        "* __Dimensionality Reduction__\n",
        "    - [Feature Extraction](https://www.kaggle.com/c/vsb-power-line-fault-detection/discussion/78285)\n",
        "    - [Manifold Learning](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)\n",
        "\n",
        "We've already seen *representation learning* when we talked about word embedding modelings during our NLP week. Today we're going to achieve a similiar goal on images using *autoencoders*. An autoencoder is a neural network that is trained to attempt to copy its input to its output. Usually they are restricted in ways that allow them to copy only approximately. The model often learns useful properties of the data, because it is forced to prioritize which aspecs of the input should be copied. The properties of autoencoders have made them an important part of modern generative modeling approaches. Consider autoencoders a special case of feed-forward networks (the kind we've been studying); backpropagation and gradient descent still work. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDOddguraAIn",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoder Architecture (Learn)\n",
        "<a id=\"p1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGkJ4JjwaAIo",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The *encoder* compresses the input data and the *decoder* does the reverse to produce the uncompressed version of the data to create a reconstruction of the input as accurately as possible:\n",
        "\n",
        "<img src='https://miro.medium.com/max/1400/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png' width=800/>\n",
        "\n",
        "The learning process gis described simply as minimizing a loss function: \n",
        "$ L(x, g(f(x))) $\n",
        "\n",
        "- $L$ is a loss function penalizing $g(f(x))$ for being dissimiliar from $x$ (such as mean squared error)\n",
        "- $f$ is the encoder function\n",
        "- $g$ is the decoder function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mEmb17qaAIp",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along\n",
        "### Extremely Simple Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXILNAQvaAIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# this is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# this is our input placeholder\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9M4rua5aAIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPOiKcYzaAIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Seperate Decoder Model (Demo Only)\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNYTtYDZaAIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.compile(optimizer='nadam', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZBPMmDZaAI2",
        "colab_type": "code",
        "outputId": "7529f66e-6ae5-4ecc-c0a8-7a6f1970e819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57sRTAcWaAI5",
        "colab_type": "code",
        "outputId": "5fe9ab37-8afc-48c1-b980-580455dddfd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0aAMUZJaAI9",
        "colab_type": "code",
        "outputId": "50e79dbc-85a4-4a83-e3f8-de6175741fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=1000,\n",
        "                batch_size=500,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                verbose = True\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0972 - val_loss: 0.0956\n",
            "Epoch 2/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0966 - val_loss: 0.0951\n",
            "Epoch 3/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0962 - val_loss: 0.0947\n",
            "Epoch 4/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0958 - val_loss: 0.0944\n",
            "Epoch 5/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0955 - val_loss: 0.0941\n",
            "Epoch 6/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0952 - val_loss: 0.0938\n",
            "Epoch 7/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0950 - val_loss: 0.0935\n",
            "Epoch 8/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0947 - val_loss: 0.0934\n",
            "Epoch 9/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0946 - val_loss: 0.0931\n",
            "Epoch 10/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0944 - val_loss: 0.0930\n",
            "Epoch 11/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0942 - val_loss: 0.0928\n",
            "Epoch 12/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0941 - val_loss: 0.0927\n",
            "Epoch 13/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0940 - val_loss: 0.0926\n",
            "Epoch 14/1000\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0939 - val_loss: 0.0925\n",
            "Epoch 15/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0938 - val_loss: 0.0925\n",
            "Epoch 16/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0937 - val_loss: 0.0924\n",
            "Epoch 17/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0936 - val_loss: 0.0923\n",
            "Epoch 18/1000\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0936 - val_loss: 0.0922\n",
            "Epoch 19/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0935 - val_loss: 0.0922\n",
            "Epoch 20/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0934 - val_loss: 0.0922\n",
            "Epoch 21/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0934 - val_loss: 0.0921\n",
            "Epoch 22/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0933 - val_loss: 0.0920\n",
            "Epoch 23/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0933 - val_loss: 0.0920\n",
            "Epoch 24/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0932 - val_loss: 0.0919\n",
            "Epoch 25/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0932 - val_loss: 0.0919\n",
            "Epoch 26/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0932 - val_loss: 0.0918\n",
            "Epoch 27/1000\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0931 - val_loss: 0.0918\n",
            "Epoch 28/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0931 - val_loss: 0.0918\n",
            "Epoch 29/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 30/1000\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 31/1000\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0930 - val_loss: 0.0917\n",
            "Epoch 32/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 33/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 34/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0929 - val_loss: 0.0916\n",
            "Epoch 35/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0929 - val_loss: 0.0916\n",
            "Epoch 36/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 37/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 38/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 39/1000\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0928 - val_loss: 0.0918\n",
            "Epoch 40/1000\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 41/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 42/1000\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 43/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 44/1000\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 45/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 46/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0927 - val_loss: 0.0914\n",
            "Epoch 47/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 48/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 49/1000\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 50/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 51/1000\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 52/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 53/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 54/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 55/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0926 - val_loss: 0.0913\n",
            "Epoch 56/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0925 - val_loss: 0.0914\n",
            "Epoch 57/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0925 - val_loss: 0.0914\n",
            "Epoch 58/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0925 - val_loss: 0.0914\n",
            "Epoch 59/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0925 - val_loss: 0.0914\n",
            "Epoch 60/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0925 - val_loss: 0.0914\n",
            "Epoch 61/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0925 - val_loss: 0.0914\n",
            "Epoch 62/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0925 - val_loss: 0.0913\n",
            "Epoch 63/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0925 - val_loss: 0.0913\n",
            "Epoch 64/1000\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0925 - val_loss: 0.0913\n",
            "Epoch 65/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0925 - val_loss: 0.0913\n",
            "Epoch 66/1000\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0924 - val_loss: 0.0913\n",
            "Epoch 67/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0924 - val_loss: 0.0913\n",
            "Epoch 68/1000\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0924 - val_loss: 0.0913\n",
            "Epoch 69/1000\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0924 - val_loss: 0.0914\n",
            "Epoch 70/1000\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0924 - val_loss: 0.0913\n",
            "Epoch 71/1000\n",
            "40500/60000 [===================>..........] - ETA: 0s - loss: 0.0924"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9e7eac62de02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Oa6uqZaAJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "decoded_imgs = autoencoder.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzhaQdy9mU5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT3jW9mkmuKj",
        "colab_type": "code",
        "outputId": "1dd3e314-6d33-4a16-cf5f-71ae140fbc77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "encoded_imgs[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.48319793, 0.5526848 , 0.83522314, 0.        , 0.7630882 ,\n",
              "       0.33297333, 1.9542437 , 1.6074824 , 0.        , 0.        ,\n",
              "       0.14159285, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.8093289 ,\n",
              "       1.368315  , 0.        , 0.12443443, 1.9688    , 0.        ,\n",
              "       0.13018142, 0.        , 0.41584224, 0.        , 0.        ,\n",
              "       1.4257993 , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN5YO6kwaAJC",
        "colab_type": "code",
        "outputId": "cd1e5c87-8ef7-431d-cf87-cd570543a976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABG0AAADnCAYAAACkCqtqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z15qIqaaaAJF",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Expected to talk about the components of autoencoder and their purpose. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftexIWpkaAJG",
        "colab_type": "text"
      },
      "source": [
        "# Train an Autoencoder (Learn)\n",
        "<a id=\"p2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O65pNEtzaAJG",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "As long as our architecture maintains an hourglass shape, we can continue to add layers and create a deeper network. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "qHGbC9YCaAJH",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv4SYSyaaAJI",
        "colab_type": "text"
      },
      "source": [
        "### Deep Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZieIdl3kaAJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(784,))\n",
        "\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded) # => Our dry strawberry\n",
        "\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51sS_FMKaAJM",
        "colab_type": "code",
        "outputId": "b9320e11-269a-47c2-8773-0b121fe8d55a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile & fit model\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "stop_parms = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "autoencoder.compile(optimizer='nadam',\n",
        "                    loss='binary_crossentropy'\n",
        "                    )\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=1000,\n",
        "                batch_size=500,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                verbose = True\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2808 - val_loss: 0.2029\n",
            "Epoch 2/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1848 - val_loss: 0.1702\n",
            "Epoch 3/1000\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1642 - val_loss: 0.1573\n",
            "Epoch 4/1000\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1522 - val_loss: 0.1475\n",
            "Epoch 5/1000\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1436 - val_loss: 0.1378\n",
            "Epoch 6/1000\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1369 - val_loss: 0.1340\n",
            "Epoch 7/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1317 - val_loss: 0.1270\n",
            "Epoch 8/1000\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1273 - val_loss: 0.1213\n",
            "Epoch 9/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1244 - val_loss: 0.1233\n",
            "Epoch 10/1000\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1217 - val_loss: 0.1176\n",
            "Epoch 11/1000\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1194 - val_loss: 0.1183\n",
            "Epoch 12/1000\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1175 - val_loss: 0.1164\n",
            "Epoch 13/1000\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1158 - val_loss: 0.1152\n",
            "Epoch 14/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1142 - val_loss: 0.1129\n",
            "Epoch 15/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1127 - val_loss: 0.1101\n",
            "Epoch 16/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1114 - val_loss: 0.1078\n",
            "Epoch 17/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1100 - val_loss: 0.1072\n",
            "Epoch 18/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1087 - val_loss: 0.1058\n",
            "Epoch 19/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1076 - val_loss: 0.1059\n",
            "Epoch 20/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1067 - val_loss: 0.1045\n",
            "Epoch 21/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1059 - val_loss: 0.1048\n",
            "Epoch 22/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1047 - val_loss: 0.1033\n",
            "Epoch 23/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1040 - val_loss: 0.1019\n",
            "Epoch 24/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1032 - val_loss: 0.1021\n",
            "Epoch 25/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1024 - val_loss: 0.1004\n",
            "Epoch 26/1000\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1018 - val_loss: 0.0992\n",
            "Epoch 27/1000\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1011 - val_loss: 0.0991\n",
            "Epoch 28/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1005 - val_loss: 0.0997\n",
            "Epoch 29/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1000 - val_loss: 0.1034\n",
            "Epoch 30/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0993 - val_loss: 0.0987\n",
            "Epoch 31/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0988 - val_loss: 0.0980\n",
            "Epoch 32/1000\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.0985 - val_loss: 0.0978\n",
            "Epoch 33/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0977 - val_loss: 0.0967\n",
            "Epoch 34/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0976 - val_loss: 0.0988\n",
            "Epoch 35/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0970 - val_loss: 0.0952\n",
            "Epoch 36/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0966 - val_loss: 0.0959\n",
            "Epoch 37/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0963 - val_loss: 0.0945\n",
            "Epoch 38/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0959 - val_loss: 0.0955\n",
            "Epoch 39/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0956 - val_loss: 0.0967\n",
            "Epoch 40/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0951 - val_loss: 0.0934\n",
            "Epoch 41/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0949 - val_loss: 0.0924\n",
            "Epoch 42/1000\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0945 - val_loss: 0.0942\n",
            "Epoch 43/1000\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0945 - val_loss: 0.0932\n",
            "Epoch 44/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0939 - val_loss: 0.0935\n",
            "Epoch 45/1000\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0936 - val_loss: 0.0929\n",
            "Epoch 46/1000\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0933 - val_loss: 0.0928\n",
            "Epoch 47/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0932 - val_loss: 0.0920\n",
            "Epoch 48/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0927 - val_loss: 0.0914\n",
            "Epoch 49/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0923 - val_loss: 0.0909\n",
            "Epoch 50/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0922 - val_loss: 0.0917\n",
            "Epoch 51/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0919 - val_loss: 0.0909\n",
            "Epoch 52/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0917 - val_loss: 0.0904\n",
            "Epoch 53/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0913 - val_loss: 0.0920\n",
            "Epoch 54/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0911 - val_loss: 0.0903\n",
            "Epoch 55/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0908 - val_loss: 0.0893\n",
            "Epoch 56/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0906 - val_loss: 0.0906\n",
            "Epoch 57/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0903 - val_loss: 0.0890\n",
            "Epoch 58/1000\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.0899 - val_loss: 0.0896\n",
            "Epoch 59/1000\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.0898 - val_loss: 0.0884\n",
            "Epoch 60/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0896 - val_loss: 0.0885\n",
            "Epoch 61/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0893 - val_loss: 0.0890\n",
            "Epoch 62/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0891 - val_loss: 0.0879\n",
            "Epoch 63/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0888 - val_loss: 0.0890\n",
            "Epoch 64/1000\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0887 - val_loss: 0.0884\n",
            "Epoch 65/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0885 - val_loss: 0.0880\n",
            "Epoch 66/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0882 - val_loss: 0.0870\n",
            "Epoch 67/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0880 - val_loss: 0.0874\n",
            "Epoch 68/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0879 - val_loss: 0.0875\n",
            "Epoch 69/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0878 - val_loss: 0.0868\n",
            "Epoch 70/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0875 - val_loss: 0.0869\n",
            "Epoch 71/1000\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0874 - val_loss: 0.0867\n",
            "Epoch 72/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0872 - val_loss: 0.0876\n",
            "Epoch 73/1000\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.0870 - val_loss: 0.0868\n",
            "Epoch 74/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0868 - val_loss: 0.0858\n",
            "Epoch 75/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0867 - val_loss: 0.0860\n",
            "Epoch 76/1000\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0866 - val_loss: 0.0855\n",
            "Epoch 77/1000\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0864 - val_loss: 0.0854\n",
            "Epoch 78/1000\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0862 - val_loss: 0.0864\n",
            "Epoch 79/1000\n",
            "22500/60000 [==========>...................] - ETA: 2s - loss: 0.0862"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1b1c35c62f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5quQK7Zsbqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8NEGXMWaAJP",
        "colab_type": "code",
        "outputId": "a74fb95e-e330-4a6e-89e0-bce59cfd662e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABG0AAADnCAYAAACkCqtqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAjEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3AA6A17smK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "KZnILGbhaAJS",
        "colab_type": "text"
      },
      "source": [
        "### Convolutional autoencoder\n",
        "\n",
        "> Since our inputs are images, it makes sense to use convolutional neural networks (convnets) as encoders and decoders. In practical settings, autoencoders applied to images are always convolutional autoencoders --they simply perform much better.\n",
        "\n",
        "> Let's implement one. The encoder will consist in a stack of Conv2D and MaxPooling2D layers (max pooling being used for spatial down-sampling), while the decoder will consist in a stack of Conv2D and UpSampling2D layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNUr3LVHaAJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Create Model\n",
        "input_img = Input(shape=(28,28,1))\n",
        "\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2,2), padding='same')(x)\n",
        "x = Conv2D(8, (3,3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2,2), padding='same')(x)\n",
        "x = Conv2D(8, (3,3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2,2), padding='same')(x)\n",
        "# ^ this is the representation. The shape (4,4,8) => 128 dimensional representation\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3,3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='nadam', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhfH1kMSvNFa",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqxl3Oi_aAJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APrUl8ZwaAJX",
        "colab_type": "code",
        "outputId": "31c7f176-42e6-4f66-a185-02f6785bb47a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                verbose=True\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.2529 - val_loss: 0.1748\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.1660 - val_loss: 0.1618\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.1529 - val_loss: 0.1448\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.1446 - val_loss: 0.1409\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.1385 - val_loss: 0.1341\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.1337\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2d7c2ccdd232>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    371\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m    372\u001b[0m                                  prefix='val_')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxsCmNswaAJZ",
        "colab_type": "code",
        "outputId": "800d66f9-f30d-454c-c8dd-35b601596dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n + 1)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABG0AAADnCAYAAACkCqtqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPmhmavpaAJb",
        "colab_type": "text"
      },
      "source": [
        "#### Visualization of the Representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwGhBZmgaAJc",
        "colab_type": "code",
        "outputId": "b290f317-5118-44ab-9cdb-3dd3a01671d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "encoder = Model(input_img, encoded)\n",
        "encoder.predict(x_train)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i+n)\n",
        "    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-b8fd0c97777e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 32 into shape (4,32)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIsAAAHWCAYAAABHfnpiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9WcdMGEaAJe",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will train an autoencoder at some point in the near future. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG1SfYkNaAJf",
        "colab_type": "text"
      },
      "source": [
        "# Information Retrieval with Autoencoders (Learn)\n",
        "<a id=\"p3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP8FBBw1aAJg",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "A common usecase for autoencoders is for reverse image search. Let's try to draw an image and see what's most similiar in our dataset. \n",
        "\n",
        "To accomplish this we will need to slice our autoendoer in half to extract our reduced features. :) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_FVohXvaAJh",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDIhqkC4aAJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Model(input_img, encoded)\n",
        "encoded_imgs = encoder.predict(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ6wry84aAJj",
        "colab_type": "code",
        "outputId": "275a8253-c8f8-47a6-a037-2576274231f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "encoded_imgs[0].reshape(128,1).T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.58063287, 0.33374   , 0.        , 1.3409522 , 3.9547582 ,\n",
              "        1.9529352 , 2.0571866 , 3.3837879 , 0.        , 3.0849602 ,\n",
              "        0.        , 3.643327  , 5.9826565 , 4.7828536 , 5.126752  ,\n",
              "        2.8535876 , 1.3060819 , 2.8466477 , 0.        , 3.5047734 ,\n",
              "        5.0695634 , 4.017003  , 4.9246836 , 2.5028923 , 1.5217009 ,\n",
              "        1.2942343 , 0.81634426, 1.8499422 , 0.7648286 , 2.1821187 ,\n",
              "        2.6313896 , 0.        , 0.8882898 , 1.0850819 , 2.7956877 ,\n",
              "        0.6594243 , 3.5469182 , 0.13664852, 1.5429838 , 3.2300138 ,\n",
              "        1.1241021 , 3.4774215 , 0.72227067, 2.4533923 , 4.037189  ,\n",
              "        4.86583   , 5.3456044 , 5.6668215 , 2.2747092 , 3.230202  ,\n",
              "        1.5190359 , 3.0670507 , 3.5331142 , 5.7752457 , 4.8403463 ,\n",
              "        4.0193048 , 1.6910295 , 1.1573455 , 1.121399  , 1.1899979 ,\n",
              "        0.04417678, 1.4572923 , 1.2076576 , 1.754942  , 0.64247924,\n",
              "        1.7836349 , 0.        , 2.2778554 , 5.7859497 , 3.3605704 ,\n",
              "        3.7747588 , 3.5113635 , 1.064366  , 3.3485003 , 2.557106  ,\n",
              "        3.5873013 , 6.191205  , 4.073557  , 4.7446117 , 5.407203  ,\n",
              "        2.5661678 , 2.9813066 , 1.937922  , 1.5257952 , 3.395628  ,\n",
              "        3.9367836 , 5.8339767 , 2.3253403 , 1.375007  , 0.9394037 ,\n",
              "        1.5797805 , 0.27206603, 0.26094612, 2.1088192 , 0.9100591 ,\n",
              "        1.0415379 , 0.37444502, 1.4862696 , 1.9521639 , 0.1985818 ,\n",
              "        2.6302946 , 0.        , 3.8562744 , 1.7830553 , 2.093813  ,\n",
              "        2.535173  , 2.6181695 , 0.05929581, 0.9658796 , 1.5629517 ,\n",
              "        3.5744648 , 2.2533767 , 2.1746478 , 1.3481349 , 2.1931362 ,\n",
              "        0.9901093 , 0.        , 1.965963  , 0.5293027 , 3.037749  ,\n",
              "        0.46442688, 0.03803341, 0.4974424 , 0.485115  , 0.        ,\n",
              "        0.22611678, 0.70066124, 0.7025563 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RK3-wm50yr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = encoded_imgs.reshape((encoded_imgs.shape[0],128))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AjW3B6R1xJV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtjZBkgU0-PX",
        "colab_type": "code",
        "outputId": "a148aa41-5d13-40e8-b7bf-35ead538ac20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHyZV_1CaAJl",
        "colab_type": "code",
        "outputId": "2c222170-eb1d-41fd-87db-6389a65b9ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=10, algorithm='ball_tree')\n",
        "nn.fit(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT7dL2QFaAJn",
        "colab_type": "code",
        "outputId": "5911ffbd-18e4-4af3-fd1f-00acdc0bac44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test = encoder.predict(x_test)\n",
        "test = test.reshape(test.shape[0], 128)\n",
        "\n",
        "nn.kneighbors([test[723]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[4.31662356, 4.33594876, 4.3927486 , 4.44810645, 4.4626366 ,\n",
              "         4.48765994, 4.66355266, 4.74760191, 4.77527277, 4.80795838]]),\n",
              " array([[ 3964, 56050, 19080, 16540, 22744, 38540,   666, 21256, 17508,\n",
              "         37510]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCLOkTG22aoP",
        "colab_type": "code",
        "outputId": "38bc744c-7842-49aa-b8ad-33300adf5d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "search_image = test[0]\n",
        "\n",
        "plt.imshow(x_test[723].reshape(28,28))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f569415db70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBGEHkiDsQBL/D7eSJVPHedbDAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hgn2qKE2ahO",
        "colab_type": "code",
        "outputId": "d2c20cea-8c52-46b8-da11-fab6897ab9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "best_response = train[47003]\n",
        "plt.imshow(x_train[3964].reshape(28,28))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f569a1b6c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocBifa-4aAJp",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You should already be familiar with KNN and similarity queries, so the key component of this section is know what to 'slice' from your autoencoder (the encoder) to extract features from your data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z9u_soPaAJq",
        "colab_type": "text"
      },
      "source": [
        "# Review\n",
        "\n",
        "* <a href=\"#p1\">Part 1</a>: Describe the componenets of an autoencoder\n",
        "    - Enocder\n",
        "    - Decoder\n",
        "* <a href=\"#p2\">Part 2</a>: Train an autoencoder\n",
        "    - Can do in Keras Easily\n",
        "    - Can use a variety of architectures\n",
        "    - Architectures must follow hourglass shape\n",
        "* <a href=\"#p3\">Part 3</a>: Apply an autoenocder to a basic information retrieval problem\n",
        "    - Extract just the encoder to use for various tasks\n",
        "    - AE ares good for dimensionality reduction, reverse image search, and may more things. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzbarwugaAJq",
        "colab_type": "text"
      },
      "source": [
        "# Sources\n",
        "\n",
        "__References__\n",
        "- [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
        "- [Deep Learning Cookbook](http://shop.oreilly.com/product/0636920097471.do)\n",
        "\n",
        "__Additional Material__"
      ]
    }
  ]
}