{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "with open(\"dkm.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = list(set(text))\n",
    "\n",
    "i_to_c = {i: c for i, c in enumerate(chars)}\n",
    "c_to_i = {c: i for i, c in enumerate(chars)}\n",
    "\n",
    "encoded = [c_to_i[c] for c in text]\n",
    "sequences = []\n",
    "next_char = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 30\n",
    "step = 5\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    text = re.sub(\"[^A-Za-z0-9 ]\", \"\", text)\n",
    "    \n",
    "    encoded = [c_to_i[c] for c in text]\n",
    "    for i in range(0, len(encoded) - maxlen, step):\n",
    "        sequences.append(encoded[i : i + maxlen])\n",
    "        next_char.append(encoded[i + maxlen])\n",
    "\n",
    "\n",
    "    for i in range(0, len(encoded) - maxlen, step):\n",
    "        sequences.append(encoded[i : i + maxlen])\n",
    "        next_char.append(encoded[i + maxlen])\n",
    "    X = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "    for i, seq in enumerate(sequences):\n",
    "        for t, char in enumerate(seq):\n",
    "            X[i, t, char] = 1\n",
    "        y[i, next_char[i]] = 1\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112202, 30, 89)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "X, y = preprocess(text)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 89)                63724     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 89)                8010      \n",
      "=================================================================\n",
      "Total params: 71,734\n",
      "Trainable params: 71,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "max_features = 20000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(len(chars), input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, c_to_i[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = i_to_c[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "876/877 [============================>.] - ETA: 0s - loss: 2.1171\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"We're out of our minds â¨And \"\n",
      "We're out of our minds â¨And Slofersely At Wiseig Till torech your hak dard nougnt and lawd the af im in Wis ther cruttitthe ming a sard the Bon hor Sfatiny Hally syral I never Yar I gum sayl ot dous and chean thein watl: hontis shing Cwakr soo BlisS otay brwesr Sreponge the porreeg Jock Drocthen sall Thane Chourdt of ardred illicht llly comw wale tish eane wack you of rat ame the ith Lwa ca chong yom hay noo mpall tou ness I\n",
      "877/877 [==============================] - 28s 32ms/step - loss: 2.1169\n",
      "Epoch 2/3\n",
      "697/877 [======================>.......] - ETA: 3s - loss: 2.0380"
     ]
    }
   ],
   "source": [
    "import random, sys\n",
    "\n",
    "model.fit(X, y, batch_size=128, epochs=3, callbacks=[print_callback],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lambda_venv",
   "language": "python",
   "name": "lambda_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
